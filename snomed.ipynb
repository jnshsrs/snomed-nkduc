{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the NKDUC to SNOMED Mapping\n",
    "\n",
    "This script contains the code and the results of our analysis for our mapping of NKDUC items to SNOMED CT.\n",
    "We analysed the reliability of the mapping and the coverage rate of SNOMED CT for the NKDUC.\n",
    "\n",
    "The information about the NKDUC and the cross map is available as csv file in the subfolder <code>./data</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script includes the following sections:\n",
    "1. Load Data\n",
    "2. Compute Reliability of the mapping (Fleiss Kappa)\n",
    "3. Compute the Reliability of the equivalence Rating\n",
    "4. Compute the Coverage Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping\n",
    "import pandas as pd\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "import numpy as np\n",
    "res = pd.read_csv(\"./data/mapping-results.csv\")\n",
    "\n",
    "# res.finales_konzept = res.finales_konzept.map({1: True, 1: False}).astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode Kapitel\n",
    "chapters_de = {\n",
    "    1: \"Stammdaten\",\n",
    "    2: \"Allgemeinstatus\",\n",
    "    3: \"Wundanamnese\",\n",
    "    4: \"Wundstatus\",\n",
    "    5: \"Diagnostik\",\n",
    "    6: \"Therapie\",\n",
    "    7: \"Patient Related Outcome (PRO)\",\n",
    "    8: \"Ern√§hrung\",\n",
    "    9: \"Edukation\"\n",
    "}\n",
    "\n",
    "res.kapitel = res.kapitel.map(chapters_de)\n",
    "res.kapitel = res.kapitel.astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of items in the chapters\n",
    "n_chapter = res.loc[:, ['kapitelbezeichnung', 'id']].drop_duplicates('id').groupby('kapitelbezeichnung').count()\n",
    "#n_overall = res.loc[:, ['id']].drop_duplicates('id').shape[0]\n",
    "#pd.DataFrame({n_overall, index=['Overall']})\n",
    "n_chapter.loc['Overall'] = n_chapter.sum(axis=0)\n",
    "n_chapter.columns = ['n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalence Labels\n",
    "equ_cat = res.equ_jens.drop_duplicates().sort_values()\n",
    "iso_categories = {\n",
    "    'Equivalence of meaning; lexical, as well as conceptual': 1,\n",
    "    'Equivalence of meaning, but with synonymy.': 2,\n",
    "    'Source concept is broader and has a less specific meaning than the target concept': 3,\n",
    "    'Source concept is narrower and has a more specific meaning than the target concept': 4,\n",
    "    'No map is possible': 5, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability of the Mapping\n",
    "### Proportional Agreement between Mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = res.pivot(index = \"id\", columns= \"id_mapper\", values= \"snomed_code\")\n",
    "mapping.columns = [\"map1\", \"map2\", \"map3\"]\n",
    "\n",
    "mapping['agree2'] = mapping.iloc[:, 1] == mapping.iloc[:, 2]\n",
    "mapping['agree3'] = mapping.iloc[:, 0] == mapping.iloc[:, 2]\n",
    "mapping['agree1'] = mapping.iloc[:, 0] == mapping.iloc[:, 1]\n",
    "\n",
    "mapping.loc[:, 'agreement_perc'] = mapping.loc[:, ['agree1', 'agree2', 'agree3']].astype('int').sum(axis=1) / 3\n",
    "mapping = res.loc[:, ['id', 'kapitelbezeichnung']].merge(right=mapping.reset_index(), on='id')\n",
    "\n",
    "agree = mapping.loc[:, ['kapitelbezeichnung', 'agreement_perc']].groupby('kapitelbezeichnung').apply(np.mean)\n",
    "\n",
    "agree.loc['Overall'] = mapping.agreement_perc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fleiss-Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_for_fleiss_kappa(data, index='id', columns='snomed_code', n_rater=3):\n",
    "    \"\"\"\n",
    "    Restructures the dataframe to compute the Fleiss Kappa Value\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.DataFrame\n",
    "        A dataframe with columns snomed_code, id (the item id of the nkduc items)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array\n",
    "        A numpy array, which columns represent the snomed_ct code and rows an item of the NKDUC\n",
    "        The values in the cells represent the number of raters, who chose the code for the NKDUC items\n",
    "    \"\"\"\n",
    "    # Reshape data\n",
    "    # add a column with only ones (to count the number of agreements)\n",
    "    data.loc[:, 'cnt'] = np.array([1 for i in range(data.shape[0])]) \n",
    "    # To compute fleiss kappa, the data has to be reshaped into a structure \n",
    "    # in which nkduc items are in the rows and each snomed concept is in a col\n",
    "    agreement = data.pivot_table(values='cnt', index=index, columns=columns, aggfunc='sum', fill_value = 0) # reshape data\n",
    "    # print(np.array(agreement).sum(axis=1))\n",
    "    assert all(np.array(agreement).sum(axis=1) == n_rater) # row sums should all be three (three ratings for each item)\n",
    "    return agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for chapter in res.kapitelbezeichnung.drop_duplicates().values:\n",
    "    df = res.loc[res.kapitelbezeichnung == chapter, :]\n",
    "    fk_result = fleiss_kappa(reshape_for_fleiss_kappa(df))\n",
    "    d[chapter] = fk_result\n",
    "    \n",
    "d['Overall'] = fleiss_kappa(reshape_for_fleiss_kappa(res))\n",
    "\n",
    "kappa = pd.DataFrame(d, index=[0]).transpose()\n",
    "kappa.columns = ['kappa']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = agree.merge(kappa, left_index = True, right_index=True).merge(n_chapter, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Mapping Reliability Results\n",
    "display(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Equivalence Rating\n",
    "\n",
    "## Fleiss-Kappa Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Kappa\n",
    "df1 = res.loc[:, ['equ_jens', 'equ_mareike']].reset_index()\n",
    "df2 = df1.melt(id_vars='index')\n",
    "df3 = df2.pivot_table(values='variable', columns='value', aggfunc='count', index='index', fill_value=0)\n",
    "kappa = {'Overall': fleiss_kappa(df3)}\n",
    "\n",
    "# Kappa by NKDUC Chapter\n",
    "for chapter in res.kapitelbezeichnung.drop_duplicates().values:\n",
    "    df1 = res.loc[res.kapitelbezeichnung == chapter, ['equ_jens', 'equ_mareike']].reset_index()\n",
    "    df2 = df1.melt(id_vars='index')\n",
    "    df3 = df2.pivot_table(values='variable', columns='value', aggfunc='count', index='index', fill_value=0)\n",
    "    kappa[chapter] = fleiss_kappa(df3)\n",
    "\n",
    "kappa = pd.DataFrame(kappa, index=[0]).transpose()\n",
    "kappa.columns = ['kappa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_chapter = res.loc[:, ['kapitelbezeichnung', 'agreement']].groupby('kapitelbezeichnung').apply(np.mean)\n",
    "agreement_overall = res.loc[:, ['agreement']].apply(np.mean)\n",
    "agreement_overall = pd.DataFrame({'Overall': agreement_overall}).transpose()\n",
    "agreement = agreement_chapter.append(agreement_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge kappa and agreement values\n",
    "agreement_kappa = pd.merge(kappa, agreement, left_index=True, right_index=True).merge(n_chapter, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Display Equivalence Rating Results\n",
    "display(agreement_kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverage Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(res.loc[:, ['id','finales_konzept']].groupby('id').count().finales_konzept == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_ids = res.drop_duplicates(['id']).loc[:, ['id']]\n",
    "df=res.loc[res.finales_konzept==1, ['id','snomed_code', 'finaler_beschluss', 'descriptor','finales_konzept']]\n",
    "df.head()\n",
    "df.groupby('id').apply(np.mean).shape[0]\n",
    "res.loc[:, ['id', 'map']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_map=res.loc[res.finales_konzept==1, ['id','snomed_code', 'descriptor', 'equi_final']].drop_duplicates()\n",
    "final_map=res.drop_duplicates('id').loc[:, ['id', 'kapitelbezeichnung', 'finaler_beschluss']].merge(final_map, on='id', how='left')\n",
    "final_map.loc[:, 'descriptor'] = final_map['descriptor'].fillna('no map')\n",
    "final_map.loc[:, 'snomed_code'] = final_map['snomed_code'].fillna('no map')\n",
    "final_map.loc[:, 'equi_final'] = final_map['equi_final'].fillna('No map is possible')\n",
    "final_map['snomed_code'] = final_map['snomed_code'].apply(lambda x: False if x == 'no map' else True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_map.pivot_table(index='kapitelbezeichnung', values='snomed_code', aggfunc=('count', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_table = final_map.pivot_table(index='equi_final', values='snomed_code', columns='kapitelbezeichnung', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array(cont_table.fillna(0)).sum()==268 # Check that 268 items are included in the coverage rate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of items (equality categories) in each chapter and each categories\n",
    "df1 = final_map.pivot_table(index=['kapitelbezeichnung', 'equi_final'], values='snomed_code', aggfunc='count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the count of items in each chapter so that the proportion of matches can be computed for\n",
    "# each chapter and each matching category\n",
    "# e.g., 12 items in 01-Allgemeinstatus had a match of category 5: no map is possible\n",
    "df2=df1.merge(n_chapter, right_index=True, left_on='kapitelbezeichnung', how='left')\n",
    "# This line actually computes the percentage/ coverage rate dependent of the chapter + category (see above)\n",
    "df2.loc[:, 'coverage_perc']=df2.snomed_code / df2.n\n",
    "\n",
    "# Pretty print\n",
    "# Add number of total items and the relative items\n",
    "l = list()\n",
    "for i in range(df2.shape[0]):\n",
    "    l.append(\"{:.1%} (n={})\".format(df2.coverage_perc[i], df2.snomed_code[i]))\n",
    "# Append the computes values as new column to pd.dataframe\n",
    "df2.loc[:, 'coverage'] = pd.Series(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(df2.groupby('kapitelbezeichnung').coverage_perc.sum().values == 1) # check if perc adds up to 1 (100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually format for display the data (pivot_wide: Chapters in cols and equi categories in the rows)\n",
    "df3=df2.pivot(index='equi_final', columns='kapitelbezeichnung', values='coverage').fillna(\"-\").reset_index()\n",
    "df3.loc[:, 'equi_final'] = df3.equi_final.astype('category')\n",
    "df3.loc[:, 'equi_final'] = df3['equi_final'].cat.reorder_categories(list(iso_categories.keys()))\n",
    "df3 = df3.sort_values(by='equi_final')\n",
    "df3.set_index('equi_final', inplace=True)\n",
    "# Display Detailled Coverage Rate\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.loc[:, 'equi_final'] = df2.equi_final.astype('category', categories=list(d.keys()), ordered=True)\n",
    "iso_categories_aggregated = {\n",
    "    'Equivalence of meaning; lexical, as well as conceptual': 'Semantic Match present (Degree 1 and 2)',\n",
    "    'Equivalence of meaning, but with synonymy.': 'Semantic Match present (Degree 1 and 2)',\n",
    "    'Source concept is broader and has a less specific meaning than the target concept': 'Semantic Asymmetry present (Degree 3 and 4)',\n",
    "    'Source concept is narrower and has a more specific meaning than the target concept': 'Semantic Asymmetry present (Degree 3 and 4)',\n",
    "    'No map is possible': 'Semantic Match absent (Degree 5)', \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_categories_agg = pd.DataFrame(iso_categories_aggregated, index=[0]).transpose().reset_index()\n",
    "iso_categories_agg.columns = ['complete', 'aggregated']\n",
    "\n",
    "equi_cats = df2.merge(iso_categories_agg, left_on='equi_final', right_on='complete', how='left')\n",
    "\n",
    "equi_cats = equi_cats.loc[:, ['kapitelbezeichnung', 'aggregated', 'snomed_code']]\n",
    "equi_cats = equi_cats.groupby(['kapitelbezeichnung', 'aggregated']).agg(np.sum)\n",
    "equi_cats = equi_cats.reset_index().merge(n_chapter, left_on='kapitelbezeichnung', right_index=True)\n",
    "equi_cats.loc[:, 'coverage_perc'] = equi_cats.snomed_code / equi_cats.n\n",
    "equi_cats\n",
    "\n",
    "\n",
    "# Pretty print (relative + absolute value in one column)\n",
    "for i in range(equi_cats.shape[0]):\n",
    "    l.append(\"{:.1%} (n={})\".format(equi_cats.coverage_perc[i], equi_cats.snomed_code[i]))\n",
    "# Append the computes values as new column to pd.dataframe\n",
    "equi_cats.loc[:, 'coverage'] = pd.Series(l)\n",
    "\n",
    "category_order = pd.Series(list(iso_categories_aggregated.values())).drop_duplicates().values\n",
    "equi_cats.loc[:, 'aggregated'] = equi_cats.aggregated.astype('category')\n",
    "equi_cats.loc[:, 'aggregated'] = equi_cats.aggregated.cat.reorder_categories(new_categories=category_order, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equi_cats_pretty = equi_cats.pivot(index='aggregated', values='coverage', columns='kapitelbezeichnung')\n",
    "# Display aggregated Coverage Rate\n",
    "display(equi_cats_pretty)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
